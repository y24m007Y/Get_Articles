{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib2 import Path\n",
    "import os\n",
    "import sys\n",
    "from langdetect import detect\n",
    "import string\n",
    "import spacy\n",
    "import re\n",
    "import demoji\n",
    "from pygments.lexers import guess_lexer\n",
    "from pprint import pprint\n",
    "\n",
    "url_patern = f\"https?://[{string.punctuation}a-zA-Z0-9]+\"\n",
    "punctual = re.sub(\"[-]\", \"\", string.punctuation) + \"？「」（）・。、’＆％＄＃”！￥【】［］『』～｜，♪♬\"\n",
    "dirpath = Path(\"data/Qiita/Train\")\n",
    "nlp = spacy.load(\"ja_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~？「」（）・。、’＆％＄＃”！￥【】［］『』～｜，♪♬'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect language: scdoc\n"
     ]
    }
   ],
   "source": [
    "code = \"def measure_length(sample):\"\n",
    "lexer = guess_lexer(code)\n",
    "print(f\"Detect language: {lexer.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('data/Qiita/Train/Qiita2022-2023自然言語処理.csv'), PosixPath('data/Qiita/Train/Qiita2022-2023画像処理.csv'), PosixPath('data/Qiita/Train/Qiita2022-2023データ分析.csv'), PosixPath('data/Qiita/Train/Qiita2022-2023機械学習.csv')]\n"
     ]
    }
   ],
   "source": [
    "files = [filepath for filepath in dirpath.iterdir()]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>like</th>\n",
       "      <th>create_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPTによる「蜘蛛の糸」のストーリー変更</td>\n",
       "      <td>['自然言語処理', '青空文庫', '芥川龍之介', 'ChatGPT']</td>\n",
       "      <td>https://qiita.com/keiarr/items/1157575e71e52b8...</td>\n",
       "      <td># はじめに\\n遠い昔、ラジオ放送でやってました。著名な作家の小説のストーリーを変えて朗読す...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>日本語LLMをPPOでファインチューニングする</td>\n",
       "      <td>['Python', '自然言語処理', 'PyTorch', 'huggingface',...</td>\n",
       "      <td>https://qiita.com/jovyan/items/c727392d6d60304...</td>\n",
       "      <td>## TL;DR\\n- 3.6Bパラメータの日本語LLMに対し全パラメータをSupervis...</td>\n",
       "      <td>62</td>\n",
       "      <td>2023-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Watson NLP Library を使ってカスタム分類を試してみる（前編）</td>\n",
       "      <td>['NLP', 'library', 'Watson', 'カテゴリ分類', 'Watson...</td>\n",
       "      <td>https://qiita.com/kabe/items/39891d1348b243087b3c</td>\n",
       "      <td>## はじめに\\n\\n昨今、各企業において、ChatGPTをはじめとした、大規模言語モデルの...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>最新LLM「Swallow」で遊んでみた</td>\n",
       "      <td>['NLP', '#アドベントカレンダー']</td>\n",
       "      <td>https://qiita.com/lychee1223/items/54c6c1daaca...</td>\n",
       "      <td>&gt; 本記事は[K3AdventCalendar2023](https://adventar....</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stanでちゃんと動くトピックモデルを考案してみた</td>\n",
       "      <td>['R', '自然言語処理', 'テキストマイニング', 'トピックモデル', 'Stan']</td>\n",
       "      <td>https://qiita.com/Gotoubun_taiwan/items/68068b...</td>\n",
       "      <td># はじめに\\n\\n皆さんの中には、私のように、StanでLDAをはじめとするトピックモデル...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ランサーズのデータをOpenAIのAPIでテキストマイニングしてみた話</td>\n",
       "      <td>['自然言語処理', 'テキストマイニング', 'AI', 'OpenAI', 'ChatG...</td>\n",
       "      <td>https://qiita.com/okada1220/items/4aeb52c88448...</td>\n",
       "      <td>この記事は、[Lancers（ランサーズ） Advent Calendar 2023](ht...</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>埋め込み表現？分散表現？どっちなの？</td>\n",
       "      <td>['自然言語処理', 'NLP', 'word2vec', 'OpenAI']</td>\n",
       "      <td>https://qiita.com/suzuki_sh/items/7776fb48585d...</td>\n",
       "      <td>word2vecやGloVe、fastTextなどを使うと、単語をベクトルにできます。\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LLAMAーINDEXの入門</td>\n",
       "      <td>['NLP', 'AI', 'ChatGPT', 'LLM', 'LlamaIndex']</td>\n",
       "      <td>https://qiita.com/LyW/items/ff5c222a3a7e0a1610d6</td>\n",
       "      <td># LLAMAーINDEX実験記録＆マニュアル\\n\\nLLAMA-INDEXは、公式ドキュメ...</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nlplotで自然言語の可視化</td>\n",
       "      <td>['Python', '自然言語処理', 'nlplot']</td>\n",
       "      <td>https://qiita.com/kujira_0120/items/f73e53b76f...</td>\n",
       "      <td>ライブラリ作成者の方のブログを参照しました。\\nhttps://www.takapy.wor...</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>自然言語処理のための動的計画法</td>\n",
       "      <td>['自然言語処理', '動的計画法', '深層学習']</td>\n",
       "      <td>https://qiita.com/rhinoceros-machinelearning/i...</td>\n",
       "      <td>本記事は、[京都大学人工知能研究会KaiRAのAdvent Calender](https:...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  \\\n",
       "0                 ChatGPTによる「蜘蛛の糸」のストーリー変更   \n",
       "1                  日本語LLMをPPOでファインチューニングする   \n",
       "2  Watson NLP Library を使ってカスタム分類を試してみる（前編）   \n",
       "3                     最新LLM「Swallow」で遊んでみた   \n",
       "4                Stanでちゃんと動くトピックモデルを考案してみた   \n",
       "5      ランサーズのデータをOpenAIのAPIでテキストマイニングしてみた話   \n",
       "6                       埋め込み表現？分散表現？どっちなの？   \n",
       "7                           LLAMAーINDEXの入門   \n",
       "8                          nlplotで自然言語の可視化   \n",
       "9                          自然言語処理のための動的計画法   \n",
       "\n",
       "                                                tags  \\\n",
       "0             ['自然言語処理', '青空文庫', '芥川龍之介', 'ChatGPT']   \n",
       "1  ['Python', '自然言語処理', 'PyTorch', 'huggingface',...   \n",
       "2  ['NLP', 'library', 'Watson', 'カテゴリ分類', 'Watson...   \n",
       "3                             ['NLP', '#アドベントカレンダー']   \n",
       "4    ['R', '自然言語処理', 'テキストマイニング', 'トピックモデル', 'Stan']   \n",
       "5  ['自然言語処理', 'テキストマイニング', 'AI', 'OpenAI', 'ChatG...   \n",
       "6            ['自然言語処理', 'NLP', 'word2vec', 'OpenAI']   \n",
       "7      ['NLP', 'AI', 'ChatGPT', 'LLM', 'LlamaIndex']   \n",
       "8                     ['Python', '自然言語処理', 'nlplot']   \n",
       "9                        ['自然言語処理', '動的計画法', '深層学習']   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://qiita.com/keiarr/items/1157575e71e52b8...   \n",
       "1  https://qiita.com/jovyan/items/c727392d6d60304...   \n",
       "2  https://qiita.com/kabe/items/39891d1348b243087b3c   \n",
       "3  https://qiita.com/lychee1223/items/54c6c1daaca...   \n",
       "4  https://qiita.com/Gotoubun_taiwan/items/68068b...   \n",
       "5  https://qiita.com/okada1220/items/4aeb52c88448...   \n",
       "6  https://qiita.com/suzuki_sh/items/7776fb48585d...   \n",
       "7   https://qiita.com/LyW/items/ff5c222a3a7e0a1610d6   \n",
       "8  https://qiita.com/kujira_0120/items/f73e53b76f...   \n",
       "9  https://qiita.com/rhinoceros-machinelearning/i...   \n",
       "\n",
       "                                                body  like   create_at  \n",
       "0  # はじめに\\n遠い昔、ラジオ放送でやってました。著名な作家の小説のストーリーを変えて朗読す...     0  2023-12-30  \n",
       "1  ## TL;DR\\n- 3.6Bパラメータの日本語LLMに対し全パラメータをSupervis...    62  2023-12-28  \n",
       "2  ## はじめに\\n\\n昨今、各企業において、ChatGPTをはじめとした、大規模言語モデルの...     1  2023-12-24  \n",
       "3  > 本記事は[K3AdventCalendar2023](https://adventar....     1  2023-12-23  \n",
       "4  # はじめに\\n\\n皆さんの中には、私のように、StanでLDAをはじめとするトピックモデル...     1  2023-12-22  \n",
       "5  この記事は、[Lancers（ランサーズ） Advent Calendar 2023](ht...     8  2023-12-21  \n",
       "6  word2vecやGloVe、fastTextなどを使うと、単語をベクトルにできます。\\n\\...     1  2023-12-19  \n",
       "7  # LLAMAーINDEX実験記録＆マニュアル\\n\\nLLAMA-INDEXは、公式ドキュメ...    10  2023-12-19  \n",
       "8  ライブラリ作成者の方のブログを参照しました。\\nhttps://www.takapy.wor...     0  2023-12-19  \n",
       "9  本記事は、[京都大学人工知能研究会KaiRAのAdvent Calender](https:...     1  2023-12-18  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(files[0], encoding='utf-8')\n",
    "df = df.drop(columns=[\"index\", \"Unnamed: 0\"], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('## はじめに\\n'\n",
      " 'AI開発プロジェクトに関しては、すでに開発手法がまとめられており、その内容を参考にプロジェクトの計画・実施をすることができます。昨年度私が携わったAIを活用したデータ分析プロジェクトにおいても、公表されている開発手法を参照しながらプロジェクトを実施しました。問題なくプロジェクト終了できました、といいたいところですが、非エンジニアのお客様とのコミュニケーションについて、さまざまな失敗をし対策を立てて解決してきました。技術的な課題を解決するより難しくプロジェクトメンバー全員で悩む時間が多かったので、今回はエンジニアではないお客様とのコミュニケーションについて経験値をまとめてみました。\\n'\n",
      " '\\n'\n",
      " '## どのようなプロジェクトだった？\\n'\n",
      " 'AIを活用したデータ分析の仕組みを作成し、実際にデータ分析を行いレポートにまとめるというプロジェクトでした。\\n'\n",
      " 'ある分野でAIを活用して新たな観点でデータ分析をしていきたい、というゆるい感じでプロジェクトが開始されました。要件の明確化と目標設定、AIが検出するデータの定義、統計処理や分析手法の検討、レポート形式や可視化方法を毎週の会議でディスカッションしながら決定していく、という進め方です。会議でのコミュニケーションが非常に重要であったというわけです。\\n'\n",
      " '## 非エンジニアのお客様とのコミュニケーションで有用であったこと\\n'\n",
      " '**プロジェクトキックオフ時に信頼関係形成開始**\\n'\n",
      " '- 人となりを知ってもらうアイスブレイク的な話などを用意し、親しみをもってもらい話しかけやすくする\\n'\n",
      " '- わかりやすい説明を心がけ一方的に話さず、お客様の発言は傾聴する\\n'\n",
      " '- お客様への興味を示し、他人事のような話し方はしない\\n'\n",
      " '\\n'\n",
      " '**ビジネス目標に対応したストーリーで説明する**\\n'\n",
      " '- '\n",
      " 'AIを利用した分析で評価軸〇〇を数値化することで、より高評価の期待できるビジネスプランを作成可能、という内容を作成し分析結果の利用の流れや重要性をわかりやすく説明する\\n'\n",
      " '\\n'\n",
      " ' **わかりやすい資料作成・説明**\\n'\n",
      " '- 図や表を用いて説明したい情報を視覚的に提示することで理解を進める\\n'\n",
      " '- 複雑な概念を説明したい場合にもなるべくシンプルな図で表す\\n'\n",
      " '- ヒアリングの際は適切な回答がすぐ得られるよう、順番や選択肢工夫した資料（ヒアリングシート）を作成する\\n'\n",
      " '- プロジェクトの中で重要な成果については強調して説明し、「腹落ちした」状態でお客様社内に成果として説明できるようになっていただく\\n'\n",
      " '\\n'\n",
      " '**適切な用語の使用**\\n'\n",
      " '- 専門用語や技術用語はできるだけ避け、一般的な言葉で説明する\\n'\n",
      " '- プロジェクト内で専門用語を使用する場合には説明を実施、用語集を作成しておき、いつでも参照できるようにする\\n'\n",
      " '\\n'\n",
      " '**プロトタイプ作成・デモンストレーション実施**\\n'\n",
      " '- プロトタイプを作成し、デモンストレーションを実施することで、実際の動作や結果を視覚的に示して効果をわかりやすくし、理解を深める\\n'\n",
      " '\\n'\n",
      " '**お客様が受け身にならないよう行動をおこしやくする**\\n'\n",
      " '- 会議にてお客様が質問や意見を発言しやすいような雰囲気をつくる\\n'\n",
      " '- 質問にはわかりやすい回答を心がける\\n'\n",
      " '- お客様が不明瞭と感じている点があれば積極的に補足説明を行う\\n'\n",
      " '- お客様の意見を取り入れるようプロジェクト内で仕組みを作成しておく\\n'\n",
      " '- 定期的に実施中ステップでの成果物（説明資料等）に対するフィードバックを確認し、誤解や課題を早期発見できるようにする\\n'\n",
      " '\\n'\n",
      " '## おわりに\\n'\n",
      " '経験値としてまとめてみると、プロジェクトマネージャーやコンサルタントとして心がけること、エンジニアがやってしまいがちな失敗を防止することが含まれていると思っています。\\n'\n",
      " 'ビジネス目標によりそい、技術的な側面をわかりやすく説明していくことで信頼関係を築いていきます。その上で目標を共有してパートナーとして協業しながらプロジェクトを進めていけるよう努めることが重要と感じました。同様のプロジェクトを現在実施中ですので、さらに充実させていきたいと考えています。\\n')\n"
     ]
    }
   ],
   "source": [
    "doc = df.loc[20].body\n",
    "pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover(text):\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = re.sub(r\"[{}]\".format(punctual), \"\", text)\n",
    "    doc = nlp(text)\n",
    "    text = \"\".join([token.lemma_.lower() for token in doc if not token.is_stop])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces(texts):\n",
    "    prepro_texts = \"\"\n",
    "    texts = re.sub(r\"\\u3000|\\t|\\r\", \"\", texts)\n",
    "    texts = re.sub(\"[0-9０-９]+\", \"\", texts)\n",
    "    sub_texts = texts.split(\"\\n\")\n",
    "    flag = False\n",
    "    is_code = \"\"\n",
    "    for text in sub_texts:\n",
    "        text = re.sub(url_patern, \"\", text)\n",
    "        is_valid = ((not bool(re.search(\"[a-zA-Zぁ-んァ-ヶ一-龥々]\", text))) or bool(re.search(\"[█]+\", text)))\n",
    "        if is_valid:\n",
    "            continue\n",
    "        ja = len(re.findall(\"[ぁ-んァ-ヶー-龥々]\", text))\n",
    "        en = len(re.findall(\"[a-zA-Z]\", text))\n",
    "        if ja > en:\n",
    "            if flag:\n",
    "                lexer = guess_lexer(is_code)\n",
    "                if lexer.name in [\"Text only\", \"Text output\"]:\n",
    "                    prepro_texts += remover(is_code)\n",
    "                is_code = \"\"\n",
    "                prepro_texts += remover(text)\n",
    "            else:\n",
    "                flag = True\n",
    "                is_code += text\n",
    "    return prepro_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ai開発プロジェクト関するすでに開発手法まとめる内容参考プロジェクト計画実施昨年度私携わるai活用データ分析プロジェクト公表開発手法参照プロジェクト実施ます問題プロジェクト終了ます非エンジニア客様コミュニケーションさまざま失敗対策立てる解決ます技術的課題解決難しいプロジェクトメンバー全員悩む時間多い今回エンジニア客様コミュニケーション経験値まとめるますai活用データ分析仕組み作成実際データ分析行うレポートまとめるプロジェクトです分野ai活用新た観点データ分析いくゆるい感じプロジェクト開始ます要件明確化目標設定ai検出データ定義統計処理分析手法検討レポート形式可視化方法毎週会議ディスカッション決定進める方会議コミュニケーション非常重要わけプロジェクトキックオフ時信頼関係形成開始ビジネス目標対応ストーリー説明適切用語使用プロトタイプ作成デモンストレーション実施客様受け身行動おこすやくする経験値まとめるみるプロジェクトマネージャーコンサルタント心がけるエンジニアしまうがち失敗防止含む思うビジネス目標そう技術的側面わかるやすい説明信頼関係築くいく上目標共有パートナー協業プロジェクト進めるいける努める重要感ずるます同様プロジェクト現在実施中充実いく考える'\n"
     ]
    }
   ],
   "source": [
    "pprint(preproces(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = [\"自然言語処理\", \"画像処理\", \"データ分析\", \"機械学習\"]\n",
    "count = 0\n",
    "\n",
    "for filepath in files:\n",
    "    df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    df.body = df.body.apply(lambda x: preproces(x))\n",
    "    df.tags = cate[count]\n",
    "    df.to_csv(dirpath.joinpath(f\"preQiita2022-2023{cate[count]}.csv\"), index=False, header=True)\n",
    "    count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
